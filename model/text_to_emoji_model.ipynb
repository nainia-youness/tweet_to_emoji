{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import emoji\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset from https://www.kaggle.com/rexhaif/emojifydata-en\n",
    "with open('./tweet_data/emojitweets-01-04-2018.txt','r',encoding = 'UTF-8') as f:\n",
    "    reader=f.readlines()[0:10000]\n",
    "    df=pd.DataFrame(data=reader,columns=[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squad arriving for Game 2 üöÄ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dude is like 5‚Äô8 140 pounds his dick was long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOLLOWERSüëá\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I CANT BREATIUHW üíÄüíÄüíÄ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Ô∏è‚É£4Ô∏è‚É£ hours 'til our schedule drops!\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0                      Squad arriving for Game 2 üöÄ\\n\n",
       "1  Dude is like 5‚Äô8 140 pounds his dick was long ...\n",
       "2                                       FOLLOWERSüëá\\n\n",
       "3                             I CANT BREATIUHW üíÄüíÄüíÄ\\n\n",
       "4            2Ô∏è‚É£4Ô∏è‚É£ hours 'til our schedule drops!\\n"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"len of dataset \",len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].str.lower()\n",
    "df['tweet']=df['tweet'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am so scared of birdsü§ß'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad arriving game üöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude like ‚Äô pounds dick long strong(always lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>followersüëá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant breatiuhw üíÄüíÄüíÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0                              squad arriving game üöÄ\n",
       "1  dude like ‚Äô pounds dick long strong(always lit...\n",
       "2                                         followersüëá\n",
       "3                                 cant breatiuhw üíÄüíÄüíÄ\n",
       "4                    Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üöÄ', 'üçÜ', 'üëá', 'üíÄ', 'NAN']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis=[]\n",
    "\n",
    "for j in range(len(df.index)):\n",
    "    exist=0\n",
    "    em=\"\"\n",
    "    for i in df['tweet'][j]:\n",
    "        if i in emoji.UNICODE_EMOJI and exist==0:\n",
    "            emojis.append(i)\n",
    "            em=i\n",
    "            exist=1\n",
    "    df['tweet'][j]=df['tweet'][j].replace(em,'')\n",
    "    if(exist==0):\n",
    "        emojis.append('NAN')\n",
    "\n",
    "emojis[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emojis'] = emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad arriving game</td>\n",
       "      <td>üöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude like ‚Äô pounds dick long strong(always lit...</td>\n",
       "      <td>üçÜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>followers</td>\n",
       "      <td>üëá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant breatiuhw</td>\n",
       "      <td>üíÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet emojis\n",
       "0                               squad arriving game       üöÄ\n",
       "1  dude like ‚Äô pounds dick long strong(always lit...      üçÜ\n",
       "2                                          followers      üëá\n",
       "3                                    cant breatiuhw       üíÄ\n",
       "4                    Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!    NAN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['emojis'] = le.fit_transform(df.emojis.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad arriving game</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude like ‚Äô pounds dick long strong(always lit...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>followers</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant breatiuhw</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  emojis\n",
       "0                               squad arriving game      545\n",
       "1  dude like ‚Äô pounds dick long strong(always lit...     158\n",
       "2                                          followers     293\n",
       "3                                    cant breatiuhw      330\n",
       "4                    Ô∏è‚É£Ô∏è‚É£ hours 'til schedule drops!       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['üòÇ' 'üíñ' '‚ù§' 'üòÇ']\n",
      "469 469\n"
     ]
    }
   ],
   "source": [
    "print(le.inverse_transform(df['emojis'][8:12]))\n",
    "print(df['emojis'][8],df['emojis'][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of classes is  633\n"
     ]
    }
   ],
   "source": [
    "#number of classes\n",
    "print('the number of classes is ',len(le.classes_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        378,    1, 2301, 3705,  826,  250,  720,   56,  162, 1657, 2302])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, split=\" \")\n",
    "tokenizer.fit_on_texts(df['tweet'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['tweet'].values)#transforms each word to a integer from the word_index dictionary.\n",
    "X = pad_sequences(X) # padding our text vector so they all have the same length\n",
    "\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 256, input_length=X.shape[1]))#256 is the number of neurons,5000 is the max number of words\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.3,recurrent_dropout=0.2))\n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 22, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 22, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 633)               162681    \n",
      "=================================================================\n",
      "Total params: 2,493,305\n",
      "Trainable params: 2,493,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['emojis']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 - 60s - loss: 5.1907 - accuracy: 0.1147 - val_loss: 5.0051 - val_accuracy: 0.1200\n",
      "Epoch 2/25\n",
      "250/250 - 59s - loss: 4.9553 - accuracy: 0.1181 - val_loss: 4.8901 - val_accuracy: 0.1510\n",
      "Epoch 3/25\n",
      "250/250 - 58s - loss: 4.6337 - accuracy: 0.1640 - val_loss: 4.6974 - val_accuracy: 0.1770\n",
      "Epoch 4/25\n",
      "250/250 - 59s - loss: 4.1890 - accuracy: 0.2176 - val_loss: 4.6042 - val_accuracy: 0.2015\n",
      "Epoch 5/25\n",
      "250/250 - 60s - loss: 3.7804 - accuracy: 0.2731 - val_loss: 4.5619 - val_accuracy: 0.2410\n",
      "Epoch 6/25\n",
      "250/250 - 61s - loss: 3.4397 - accuracy: 0.3260 - val_loss: 4.6681 - val_accuracy: 0.2555\n",
      "Epoch 7/25\n",
      "250/250 - 57s - loss: 3.1360 - accuracy: 0.3766 - val_loss: 4.6822 - val_accuracy: 0.2710\n",
      "Epoch 8/25\n",
      "250/250 - 62s - loss: 2.8792 - accuracy: 0.4155 - val_loss: 4.8059 - val_accuracy: 0.2785\n",
      "Epoch 9/25\n",
      "250/250 - 59s - loss: 2.6606 - accuracy: 0.4521 - val_loss: 4.9876 - val_accuracy: 0.2825\n",
      "Epoch 10/25\n",
      "250/250 - 63s - loss: 2.4647 - accuracy: 0.4870 - val_loss: 5.0458 - val_accuracy: 0.2865\n",
      "Epoch 11/25\n",
      "250/250 - 59s - loss: 2.2927 - accuracy: 0.5228 - val_loss: 5.1973 - val_accuracy: 0.2950\n",
      "Epoch 12/25\n",
      "250/250 - 56s - loss: 2.1243 - accuracy: 0.5521 - val_loss: 5.2923 - val_accuracy: 0.3050\n",
      "Epoch 13/25\n",
      "250/250 - 56s - loss: 1.9805 - accuracy: 0.5785 - val_loss: 5.3967 - val_accuracy: 0.3125\n",
      "Epoch 14/25\n",
      "250/250 - 56s - loss: 1.8535 - accuracy: 0.6071 - val_loss: 5.5672 - val_accuracy: 0.3080\n",
      "Epoch 15/25\n",
      "250/250 - 55s - loss: 1.7188 - accuracy: 0.6294 - val_loss: 5.6240 - val_accuracy: 0.3200\n",
      "Epoch 16/25\n",
      "250/250 - 55s - loss: 1.6014 - accuracy: 0.6536 - val_loss: 5.6695 - val_accuracy: 0.3215\n",
      "Epoch 17/25\n",
      "250/250 - 55s - loss: 1.4838 - accuracy: 0.6729 - val_loss: 5.7849 - val_accuracy: 0.3260\n",
      "Epoch 18/25\n",
      "250/250 - 55s - loss: 1.3770 - accuracy: 0.6988 - val_loss: 5.8686 - val_accuracy: 0.3355\n",
      "Epoch 19/25\n",
      "250/250 - 55s - loss: 1.2834 - accuracy: 0.7229 - val_loss: 5.9723 - val_accuracy: 0.3325\n",
      "Epoch 20/25\n",
      "250/250 - 55s - loss: 1.1958 - accuracy: 0.7369 - val_loss: 6.0885 - val_accuracy: 0.3310\n",
      "Epoch 21/25\n",
      "250/250 - 55s - loss: 1.1126 - accuracy: 0.7560 - val_loss: 6.1696 - val_accuracy: 0.3335\n",
      "Epoch 22/25\n",
      "250/250 - 55s - loss: 1.0459 - accuracy: 0.7690 - val_loss: 6.2570 - val_accuracy: 0.3415\n",
      "Epoch 23/25\n",
      "250/250 - 56s - loss: 0.9679 - accuracy: 0.7871 - val_loss: 6.3782 - val_accuracy: 0.3390\n",
      "Epoch 24/25\n",
      "250/250 - 55s - loss: 0.8961 - accuracy: 0.8080 - val_loss: 6.4537 - val_accuracy: 0.3455\n",
      "Epoch 25/25\n",
      "250/250 - 55s - loss: 0.8207 - accuracy: 0.8257 - val_loss: 6.5492 - val_accuracy: 0.3430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef8e88a730>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "model.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    8   10 1386]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['üòÄ'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([np.argmax(predictions[50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['üëÄ'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([np.argmax(y_test[50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of true values is : 686\n",
      "the number of false values is : 1314\n"
     ]
    }
   ],
   "source": [
    "T=0\n",
    "F=0\n",
    "for i in range(len(y_test)):\n",
    "    if np.argmax(predictions[i])==np.argmax(y_test[i]):\n",
    "        T+=1\n",
    "    else:\n",
    "        F+=1\n",
    "print('the number of true values is :',T)\n",
    "print('the number of false values is :',F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('text_to_emoji.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tokenizer\n",
    "import json\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save label encoder\n",
    "import pickle\n",
    "filehandler = open(\"le.obj\",\"wb\")\n",
    "pickle.dump(le,filehandler)\n",
    "filehandler.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
